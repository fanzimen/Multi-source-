当前日期和时间： 2023-03-04_17_49_10
training settings:	 lr: 0.001 momentum: 0.9 l2_decay: 0.01 optimizer: Adam seed: 2023
model architecture:
 MFSAN(
  (sharedNet): CFE(
    (conv1): Conv1d(14, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv1d(32, 64, kernel_size=(2,), stride=(1,), padding=(1,), bias=False)
    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv1d(64, 128, kernel_size=(2,), stride=(1,), bias=False)
    (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (flatten): Flatten(start_dim=1, end_dim=-1)
  )
  (sonnet1): DFE(
    (rnn): LSTM(128, 100, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)
  )
  (sonnet2): DFE(
    (rnn): LSTM(128, 100, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)
  )
  (sonnet3): DFE(
    (rnn): LSTM(128, 100, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)
  )
  (rul_fc_son1): Linear(in_features=199, out_features=1, bias=True)
  (rul_fc_son2): Linear(in_features=199, out_features=1, bias=True)
  (rul_fc_son3): Linear(in_features=199, out_features=1, bias=True)
  (avgpool): AvgPool1d(kernel_size=(2,), stride=(1,), padding=(0,))
)
FD002 FD003 FD004 to FD001
Train epochs:1.000000	
Train source1 iter: 10 [(5%)]	Loss: 0.083652	RUL_Loss: 0.062281	mmd_Loss: 0.038957	l1_Loss: 0.052909
Train source2 iter: 10 [(5%)]	Loss: 0.057985	RUL_Loss: 0.033305	mmd_Loss: 0.045936	l1_Loss: 0.060154
Train source3 iter: 10 [(5%)]	Loss: 0.188401	RUL_Loss: 0.148599	mmd_Loss: 0.062731	l1_Loss: 0.108365


Train source1 iter: 20 [(9%)]	Loss: 0.098308	RUL_Loss: 0.065183	mmd_Loss: 0.033110	l1_Loss: 0.041940
Train source2 iter: 20 [(9%)]	Loss: 0.071937	RUL_Loss: 0.031271	mmd_Loss: 0.042090	l1_Loss: 0.050046
Train source3 iter: 20 [(9%)]	Loss: 0.208477	RUL_Loss: 0.151984	mmd_Loss: 0.045219	l1_Loss: 0.082775


Train source1 iter: 30 [(14%)]	Loss: 0.105486	RUL_Loss: 0.059357	mmd_Loss: 0.034068	l1_Loss: 0.041400
Train source2 iter: 30 [(14%)]	Loss: 0.083242	RUL_Loss: 0.030744	mmd_Loss: 0.039666	l1_Loss: 0.046222
Train source3 iter: 30 [(14%)]	Loss: 0.244748	RUL_Loss: 0.165305	mmd_Loss: 0.050542	l1_Loss: 0.079428


Train source1 iter: 40 [(19%)]	Loss: 0.115330	RUL_Loss: 0.063619	mmd_Loss: 0.030342	l1_Loss: 0.039649
Train source2 iter: 40 [(19%)]	Loss: 0.096912	RUL_Loss: 0.037343	mmd_Loss: 0.033591	l1_Loss: 0.047036
Train source3 iter: 40 [(19%)]	Loss: 0.244653	RUL_Loss: 0.147529	mmd_Loss: 0.050284	l1_Loss: 0.081176


Train source1 iter: 50 [(24%)]	Loss: 0.122854	RUL_Loss: 0.061331	mmd_Loss: 0.035223	l1_Loss: 0.038993
Train source2 iter: 50 [(24%)]	Loss: 0.097968	RUL_Loss: 0.029191	mmd_Loss: 0.035991	l1_Loss: 0.046976
Train source3 iter: 50 [(24%)]	Loss: 0.263189	RUL_Loss: 0.155581	mmd_Loss: 0.050061	l1_Loss: 0.079748


Train source1 iter: 60 [(28%)]	Loss: 0.130003	RUL_Loss: 0.061894	mmd_Loss: 0.033965	l1_Loss: 0.042564
Train source2 iter: 60 [(28%)]	Loss: 0.112533	RUL_Loss: 0.034708	mmd_Loss: 0.043396	l1_Loss: 0.044051
Train source3 iter: 60 [(28%)]	Loss: 0.274205	RUL_Loss: 0.160130	mmd_Loss: 0.046712	l1_Loss: 0.081466


Train source1 iter: 70 [(33%)]	Loss: 0.145175	RUL_Loss: 0.068596	mmd_Loss: 0.041701	l1_Loss: 0.040637
Train source2 iter: 70 [(33%)]	Loss: 0.111980	RUL_Loss: 0.034751	mmd_Loss: 0.036427	l1_Loss: 0.046610
Train source3 iter: 70 [(33%)]	Loss: 0.250681	RUL_Loss: 0.130047	mmd_Loss: 0.048691	l1_Loss: 0.081016


Train source1 iter: 80 [(38%)]	Loss: 0.129996	RUL_Loss: 0.060240	mmd_Loss: 0.032008	l1_Loss: 0.040968
Train source2 iter: 80 [(38%)]	Loss: 0.121670	RUL_Loss: 0.033330	mmd_Loss: 0.043918	l1_Loss: 0.048500
Train source3 iter: 80 [(38%)]	Loss: 0.269120	RUL_Loss: 0.148999	mmd_Loss: 0.047624	l1_Loss: 0.078042


Train source1 iter: 90 [(43%)]	Loss: 0.136433	RUL_Loss: 0.061465	mmd_Loss: 0.033669	l1_Loss: 0.043436
Train source2 iter: 90 [(43%)]	Loss: 0.115948	RUL_Loss: 0.032877	mmd_Loss: 0.038631	l1_Loss: 0.046808
Train source3 iter: 90 [(43%)]	Loss: 0.285611	RUL_Loss: 0.162407	mmd_Loss: 0.046792	l1_Loss: 0.079922


Train source1 iter: 100 [(47%)]	Loss: 0.131882	RUL_Loss: 0.064371	mmd_Loss: 0.030270	l1_Loss: 0.038433
Train source2 iter: 100 [(47%)]	Loss: 0.125639	RUL_Loss: 0.034719	mmd_Loss: 0.043459	l1_Loss: 0.049066
Train source3 iter: 100 [(47%)]	Loss: 0.287484	RUL_Loss: 0.161906	mmd_Loss: 0.043910	l1_Loss: 0.083883


Train source1 iter: 110 [(52%)]	Loss: 0.137777	RUL_Loss: 0.064796	mmd_Loss: 0.033428	l1_Loss: 0.040351
Train source2 iter: 110 [(52%)]	Loss: 0.118351	RUL_Loss: 0.032572	mmd_Loss: 0.039544	l1_Loss: 0.047174
Train source3 iter: 110 [(52%)]	Loss: 0.285743	RUL_Loss: 0.153107	mmd_Loss: 0.053427	l1_Loss: 0.080661


Train source1 iter: 120 [(57%)]	Loss: 0.140039	RUL_Loss: 0.064136	mmd_Loss: 0.033114	l1_Loss: 0.043305
Train source2 iter: 120 [(57%)]	Loss: 0.114957	RUL_Loss: 0.034605	mmd_Loss: 0.034468	l1_Loss: 0.046430
Train source3 iter: 120 [(57%)]	Loss: 0.294969	RUL_Loss: 0.168590	mmd_Loss: 0.047389	l1_Loss: 0.079850


Train source1 iter: 130 [(62%)]	Loss: 0.135725	RUL_Loss: 0.062076	mmd_Loss: 0.033716	l1_Loss: 0.040244
Train source2 iter: 130 [(62%)]	Loss: 0.121624	RUL_Loss: 0.035384	mmd_Loss: 0.039449	l1_Loss: 0.047156
Train source3 iter: 130 [(62%)]	Loss: 0.297489	RUL_Loss: 0.165787	mmd_Loss: 0.049567	l1_Loss: 0.082691


Train source1 iter: 140 [(66%)]	Loss: 0.139328	RUL_Loss: 0.065111	mmd_Loss: 0.033579	l1_Loss: 0.040833
Train source2 iter: 140 [(66%)]	Loss: 0.114736	RUL_Loss: 0.031942	mmd_Loss: 0.036049	l1_Loss: 0.046963
Train source3 iter: 140 [(66%)]	Loss: 0.274661	RUL_Loss: 0.143209	mmd_Loss: 0.046883	l1_Loss: 0.084915


Train source1 iter: 150 [(71%)]	Loss: 0.138613	RUL_Loss: 0.065236	mmd_Loss: 0.033229	l1_Loss: 0.040269
Train source2 iter: 150 [(71%)]	Loss: 0.117500	RUL_Loss: 0.034773	mmd_Loss: 0.037755	l1_Loss: 0.045108
Train source3 iter: 150 [(71%)]	Loss: 0.281322	RUL_Loss: 0.150423	mmd_Loss: 0.053233	l1_Loss: 0.077880


Train source1 iter: 160 [(76%)]	Loss: 0.135812	RUL_Loss: 0.062712	mmd_Loss: 0.031725	l1_Loss: 0.041449
Train source2 iter: 160 [(76%)]	Loss: 0.112330	RUL_Loss: 0.028075	mmd_Loss: 0.038976	l1_Loss: 0.045365
Train source3 iter: 160 [(76%)]	Loss: 0.286644	RUL_Loss: 0.160110	mmd_Loss: 0.048487	l1_Loss: 0.078175


Train source1 iter: 170 [(81%)]	Loss: 0.143297	RUL_Loss: 0.065163	mmd_Loss: 0.037372	l1_Loss: 0.040812
Train source2 iter: 170 [(81%)]	Loss: 0.121280	RUL_Loss: 0.032276	mmd_Loss: 0.041312	l1_Loss: 0.047748
Train source3 iter: 170 [(81%)]	Loss: 0.306467	RUL_Loss: 0.170320	mmd_Loss: 0.051757	l1_Loss: 0.084475


Train source1 iter: 180 [(85%)]	Loss: 0.144683	RUL_Loss: 0.068763	mmd_Loss: 0.033575	l1_Loss: 0.042375
Train source2 iter: 180 [(85%)]	Loss: 0.115063	RUL_Loss: 0.032221	mmd_Loss: 0.036151	l1_Loss: 0.046724
Train source3 iter: 180 [(85%)]	Loss: 0.285346	RUL_Loss: 0.150816	mmd_Loss: 0.054453	l1_Loss: 0.080131


Train source1 iter: 190 [(90%)]	Loss: 0.131944	RUL_Loss: 0.061077	mmd_Loss: 0.031758	l1_Loss: 0.039127
Train source2 iter: 190 [(90%)]	Loss: 0.117349	RUL_Loss: 0.034118	mmd_Loss: 0.037506	l1_Loss: 0.045744
Train source3 iter: 190 [(90%)]	Loss: 0.304102	RUL_Loss: 0.171583	mmd_Loss: 0.050850	l1_Loss: 0.081701


Train source1 iter: 200 [(95%)]	Loss: 0.139146	RUL_Loss: 0.064352	mmd_Loss: 0.036020	l1_Loss: 0.038785
Train source2 iter: 200 [(95%)]	Loss: 0.114640	RUL_Loss: 0.032074	mmd_Loss: 0.035288	l1_Loss: 0.047291
Train source3 iter: 200 [(95%)]	Loss: 0.284685	RUL_Loss: 0.155027	mmd_Loss: 0.051805	l1_Loss: 0.077873


Train source1 iter: 210 [(100%)]	Loss: 0.137593	RUL_Loss: 0.061351	mmd_Loss: 0.034596	l1_Loss: 0.041653
Train source2 iter: 210 [(100%)]	Loss: 0.119698	RUL_Loss: 0.035563	mmd_Loss: 0.037864	l1_Loss: 0.046279
Train source3 iter: 210 [(100%)]	Loss: 0.289140	RUL_Loss: 0.159046	mmd_Loss: 0.049391	l1_Loss: 0.080716


Train epochs:2.000000	
Train source1 iter: 10 [(5%)]	Loss: 0.070486	RUL_Loss: 0.059687	mmd_Loss: 0.033530	l1_Loss: 0.012890
Train source2 iter: 10 [(5%)]	Loss: 0.044169	RUL_Loss: 0.031212	mmd_Loss: 0.037535	l1_Loss: 0.018161
Train source3 iter: 10 [(5%)]	Loss: 0.116723	RUL_Loss: 0.102352	mmd_Loss: 0.037457	l1_Loss: 0.024320


Train source1 iter: 20 [(9%)]	Loss: 0.080373	RUL_Loss: 0.063877	mmd_Loss: 0.027152	l1_Loss: 0.010223
Train source2 iter: 20 [(9%)]	Loss: 0.050116	RUL_Loss: 0.030265	mmd_Loss: 0.030203	l1_Loss: 0.014771
Train source3 iter: 20 [(9%)]	Loss: 0.121844	RUL_Loss: 0.098367	mmd_Loss: 0.033295	l1_Loss: 0.019894


Train source1 iter: 30 [(14%)]	Loss: 0.081129	RUL_Loss: 0.057440	mmd_Loss: 0.027829	l1_Loss: 0.010925
Train source2 iter: 30 [(14%)]	Loss: 0.057848	RUL_Loss: 0.031494	mmd_Loss: 0.027818	l1_Loss: 0.015297
Train source3 iter: 30 [(14%)]	Loss: 0.120315	RUL_Loss: 0.090268	mmd_Loss: 0.030317	l1_Loss: 0.018840


Train source1 iter: 40 [(19%)]	Loss: 0.088222	RUL_Loss: 0.060271	mmd_Loss: 0.027423	l1_Loss: 0.010409
Train source2 iter: 40 [(19%)]	Loss: 0.069450	RUL_Loss: 0.033565	mmd_Loss: 0.032691	l1_Loss: 0.015879
Train source3 iter: 40 [(19%)]	Loss: 0.141987	RUL_Loss: 0.102789	mmd_Loss: 0.032594	l1_Loss: 0.020461


Train source1 iter: 50 [(24%)]	Loss: 0.092434	RUL_Loss: 0.060652	mmd_Loss: 0.027243	l1_Loss: 0.011097
Train source2 iter: 50 [(24%)]	Loss: 0.069382	RUL_Loss: 0.031087	mmd_Loss: 0.031678	l1_Loss: 0.014518
Train source3 iter: 50 [(24%)]	Loss: 0.126481	RUL_Loss: 0.084131	mmd_Loss: 0.031258	l1_Loss: 0.019830


Train source1 iter: 60 [(28%)]	Loss: 0.094634	RUL_Loss: 0.060498	mmd_Loss: 0.028384	l1_Loss: 0.009972
Train source2 iter: 60 [(28%)]	Loss: 0.076027	RUL_Loss: 0.031539	mmd_Loss: 0.035797	l1_Loss: 0.014190
Train source3 iter: 60 [(28%)]	Loss: 0.145836	RUL_Loss: 0.099957	mmd_Loss: 0.032125	l1_Loss: 0.019426


Train source1 iter: 70 [(33%)]	Loss: 0.093615	RUL_Loss: 0.058006	mmd_Loss: 0.027847	l1_Loss: 0.010440
Train source2 iter: 70 [(33%)]	Loss: 0.074727	RUL_Loss: 0.029460	mmd_Loss: 0.034369	l1_Loss: 0.014302
Train source3 iter: 70 [(33%)]	Loss: 0.139275	RUL_Loss: 0.091360	mmd_Loss: 0.031698	l1_Loss: 0.019821


